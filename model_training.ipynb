{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data\n",
        "The data set is UNBC-McMaster Shoulder Pain Data"
      ],
      "metadata": {
        "id": "PVK6y_WGo89q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_image = \"/content/drive/MyDrive/Colab Notebooks/Dataset/Images\"\n",
        "\n",
        "if os.path.exists(path_image):\n",
        "    print(\"Path is found.\",sep=' ', end=' ', flush=True)\n",
        "    if os.scandir(path_image):\n",
        "        print(\"Folder is not empty.\")\n"
      ],
      "metadata": {
        "id": "5wr96PkZofSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecf26e85-6f1d-4d5f-c8af-2533a7769b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Path is found. Folder is not empty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install face-alignment"
      ],
      "metadata": {
        "id": "7FJ0ylMU9XF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import math\n",
        "from face_alignment import FaceAlignment\n",
        "from face_alignment import LandmarksType\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "from torchvision.transforms import functional as TF\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "6-HPgvB_qHHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data analysis\n",
        "- Show the sequence frames along with the pain score a.k.a visual analogue scale (VAS)\n",
        "\n",
        "- Show the sequence frames with along with the Prkachin and Solomon Pain Intensity (PSPI) score of each frame in a graph\n",
        "\n",
        "- Show the number of the sequence that are labeled as no pain, medium pain and severe pain in a histogram\n",
        "\n"
      ],
      "metadata": {
        "id": "cOvYI9YM_9AX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ITmsx9FQB7gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess the data\n",
        "- enhance the appearance of the face\n",
        "- align the face\n",
        "- crop the face"
      ],
      "metadata": {
        "id": "YqwWNWS27kAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class preprocess():\n",
        "    def __init__(self, frames):\n",
        "        super(preprocess, self).__init__()\n",
        "        self.frames = frames\n",
        "\n",
        "        # Select 21 frames from the video sequence for prediction\n",
        "        self.frames = self.selectFrame()\n",
        "\n",
        "        # Save the selected frames to a folder\n",
        "        self.saveFramestoFiles()\n",
        "\n",
        "        # Do landmark detection on the input frames for face recognition proposes\n",
        "        self.landmarkDetection()\n",
        "\n",
        "        # Mask the non-face area with black pixels\n",
        "        self.frames = self.maskFace()\n",
        "\n",
        "        # Tilt and align the face at centre, then crop the frames according to the face region\n",
        "        self.frames = self.tiltAlign()\n",
        "\n",
        "        for i in range (len(self.frames)):\n",
        "            cv.imwrite(f'{\"rawFrames\"}\\cropped_frame_{i}.png', cv.cvtColor(self.frames[i], cv.COLOR_BGR2RGB))\n",
        "\n",
        "        self.tensor = self.padding_normalization(24)\n",
        "\n",
        "\n",
        "\n",
        "    def landmarkDetection(self):\n",
        "        frames = self.frames\n",
        "        output = []\n",
        "        framesLandmark = []\n",
        "        model = FaceAlignment(landmarks_type=LandmarksType.TWO_D, face_detector='blazeface',\n",
        "                              face_detector_kwargs={'back_model': True}, device='cpu')\n",
        "        for n in range(0, len(frames)):\n",
        "            img = (frames[n])\n",
        "            img = img.copy()\n",
        "            landmarks = model.get_landmarks(img)\n",
        "            landmarks_tuple = []\n",
        "            if landmarks is not None:\n",
        "                # Iterate over the detected faces\n",
        "                for pred in landmarks:\n",
        "                    # Draw landmarks on the frame\n",
        "                    for point in pred:\n",
        "                        x, y = point\n",
        "                        landmarks_tuple.append((int(x), int(y)))\n",
        "                        if 0 <= x < img.shape[1] and 0 <= y < img.shape[0]:\n",
        "                            cv.circle(img, (int(x), int(y)), 2, (0, 255, 0), -1)\n",
        "\n",
        "            framesLandmark.append(landmarks_tuple)\n",
        "            output.append(img)\n",
        "        self.framesLandmark = framesLandmark\n",
        "\n",
        "    def tiltAlign(self):\n",
        "        frames = self.frames\n",
        "        output =[]\n",
        "        for i in range(len(frames)):\n",
        "            img = frames[i]\n",
        "            landmarkTuple = self.framesLandmark[i]\n",
        "            # Landmark index of reight eye and left eye are\n",
        "            right_eye_cood = [(landmarkTuple[39][0] + landmarkTuple[36][0])/2, (landmarkTuple[39][1] + landmarkTuple[36][1])/2]\n",
        "            left_eye_cood = [(landmarkTuple[45][0] + landmarkTuple[42][0])/2, (landmarkTuple[45][1] + landmarkTuple[42][1])/2]\n",
        "            x1, y1 = right_eye_cood\n",
        "            x2, y2 = left_eye_cood\n",
        "\n",
        "            a = abs(y1 - y2)\n",
        "            b = abs(x2 - x1)\n",
        "            c = math.sqrt(a * a + b * b)\n",
        "\n",
        "            cos_alpha = (b * b + c * c - a * a) / (2 * b * c)\n",
        "\n",
        "            alpha = np.arccos(cos_alpha)\n",
        "            alpha = (alpha * 180) / math.pi\n",
        "            img = Image.fromarray(img)\n",
        "            if y1>y2 :\n",
        "                alpha = -alpha\n",
        "            img = np.array(img.rotate(alpha))\n",
        "            plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
        "            output.append(img)\n",
        "        return output\n",
        "\n",
        "    def maskFace(self):\n",
        "        routes = [i for i in range (16,-1,-1)] + [i for i in range (17,26+1)]\n",
        "\n",
        "        frames = self.frames\n",
        "        output = []\n",
        "        for n in range(len(frames)):\n",
        "            routes_cod = []\n",
        "            mask = None\n",
        "            out = None\n",
        "            landmarks_tuple = self.framesLandmark[n]\n",
        "            img = (frames[n])\n",
        "            img = img.copy()\n",
        "            img2 = img.copy()\n",
        "            for i in range (0, len(routes)-1):\n",
        "                source_point = routes[i]\n",
        "                target_point = routes[i+1]\n",
        "\n",
        "                source_cod = landmarks_tuple[source_point]\n",
        "                target_cod = landmarks_tuple[target_point]\n",
        "                routes_cod.append(source_cod)\n",
        "                cv.line(img, (source_cod), (target_cod),(255,255,255),2)\n",
        "\n",
        "            routes_cod = routes_cod+[routes_cod[0]]\n",
        "\n",
        "            mask = np.zeros((img.shape[0], img.shape[1]))\n",
        "            mask = cv.fillConvexPoly(mask, np.array(routes_cod),1)\n",
        "            mask = mask.astype(np.bool_)\n",
        "            out = np.zeros_like(img)\n",
        "            out[mask] = img2[mask]\n",
        "            # plt.imshow(cv.cvtColor(out, cv.COLOR_BGR2RGB))\n",
        "            output.append(cv.cvtColor(self.cropFaceArea(out, mask), cv.COLOR_BGR2RGB))\n",
        "        return output\n",
        "\n",
        "    def cropFaceArea(self, frame, mask):\n",
        "\n",
        "        gray = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
        "        contours, _ = cv.findContours(gray, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Get the bounding box of the largest contour\n",
        "\n",
        "        largest_contour = max(contours, key=cv.contourArea)\n",
        "        x, y, w, h = cv.boundingRect(largest_contour)\n",
        "\n",
        "        # Crop the image to the size of the masked face\n",
        "        cropped_image = frame[y:y+h, x:x+w]\n",
        "\n",
        "        return cropped_image\n",
        "\n",
        "    def selectFrame(self):\n",
        "        frames = self.frames\n",
        "        return [frames[i] for i in range(0, 150, 7)]\n",
        "\n",
        "    def saveFramestoFiles(self):\n",
        "        frames = self.frames\n",
        "\n",
        "        if not os.path.exists(\"rawFrames\"):\n",
        "            os.mkdir(\"rawFrames\")\n",
        "\n",
        "        for i in range(len(frames)):\n",
        "            cv.imwrite(f'{\"rawFrames\"}\\selectedFrames_{i}.png', frames[i])\n",
        "\n",
        "\n",
        "\n",
        "    def padding_normalization(self, target_length):\n",
        "        \"\"\"\n",
        "        Preprocesses a sequence of images and pads them to a target length.\n",
        "\n",
        "        Args:\n",
        "            images (list): List of PIL images.\n",
        "            target_length (int): Desired length of the sequence after padding.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Tensor of preprocessed and padded images.\n",
        "        \"\"\"\n",
        "        # Resize the images to a consistent size\n",
        "        array_images = self.frames\n",
        "        images =[]\n",
        "\n",
        "        for image in array_images:\n",
        "            images.append((Image.fromarray(image)))\n",
        "\n",
        "        resized_images = [TF.resize((img), [224, 224]) for img in images]\n",
        "\n",
        "        # Convert the images to tensors\n",
        "        tensor_images = [TF.to_tensor(img) for img in resized_images]\n",
        "\n",
        "        # Stack the tensor images along a new dimension (sequence dimension)\n",
        "        tensor_sequence = torch.stack(tensor_images)\n",
        "\n",
        "        # Calculate the current length of the sequence\n",
        "        current_length = tensor_sequence.size(0)\n",
        "\n",
        "        # Pad the sequence if necessary\n",
        "        if current_length < target_length:\n",
        "            padding_length = target_length - current_length\n",
        "            padding = torch.zeros(padding_length, *tensor_sequence.shape[1:])\n",
        "            tensor_sequence = torch.cat((tensor_sequence, padding))\n",
        "\n",
        "        # Normalize the tensor sequence\n",
        "        # Define the mean and standard deviation values for normalization\n",
        "        mean = [0.485, 0.456, 0.406]\n",
        "        std = [0.229, 0.224, 0.225]\n",
        "\n",
        "        # Apply normalization to the tensor sequence\n",
        "        normalize = transforms.Normalize(mean=mean, std=std)\n",
        "        normalized_sequence = normalize(tensor_sequence)\n",
        "\n",
        "        return normalized_sequence\n"
      ],
      "metadata": {
        "id": "OQ_jUwym78RE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}